---
title: "ESM 244 Lab 2 - Time Series"
author: "Olivia Hemond"
format: 
  html:
    code-fold: show
    toc: true
    number-sections: true
editor: visual
execute: 
  echo: true
  message: false
  warning: false
---

```{r setup}
library(tidyverse)
library(here)
library(tsibble)
library(feasts)
library(fable)
```


# Part 1: Time series with Toolik Lake data

## Always look at your data

### Read in the data

```{r}
toolik_df <- read_csv(here('data/toolik_daily.csv'))
# note: data column is read in as a character, will need to change. all other columns are doubles

### convert data frame to time series using as_tsibble
toolik_ts <- toolik_df %>% 
  mutate(date = lubridate::mdy(date)) %>% 
  as_tsibble(key = NULL,   # if we had multiple sites, key by site
             index = date) # index is setting our time series variable

ggplot(toolik_ts, aes(x = date, y = daily_air_temp)) +
  geom_line() +
  labs(x = 'Date', y = 'Mean daily air temp (Celsius)\n at Toolik Station') # \n makes a line break
```

## Use filter_index() function to filter by date or time!

```{r}
### Filter from Dec 2010 to Jan 2011
toolik_ts %>% 
  filter_index('2018-01-01' ~ .) # . means start or end of your data
```

## Use index_by() to aggregate time series by increments

```{r}
# Can aggregate by month, week, or other increment
toolik_month <- toolik_ts %>% 
  index_by(yr_mo = ~yearmonth(.)) %>%  # identify all year-month combinations in our timeseries column
  summarize(monthly_mean_temp = mean(daily_air_temp, na.rm = TRUE)) %>%  # index_by() and summarize() can go nicely together
  ungroup() # remove any lingering groupings
```

Now let's plot this!

```{r}
ggplot(data = toolik_month, aes(x = yr_mo, y = monthly_mean_temp)) +
  geom_line()

ggplot(toolik_month, aes(x = year(yr_mo), y = monthly_mean_temp)) + # just use year
  geom_line() + 
  facet_wrap(~ month(yr_mo, label = TRUE)) + # break apart by month
  labs(x = 'Year', y = 'Annual mean air temp (Celsius)',
       title = 'Toolik Station mean annual air temperature',
       subtitle = '1988-2023',
       caption = '<put citation here>')
```


# Part 2: Time series wrangling and forecasting!

Energy usage by sector, in trillions of BTUs.

```{r}
energy_df <- read_csv(here('data/energy.csv'))
# note: yrmonth is stored as a character, need to convert to date
```

### Analysis goals:

* Examine patterns and trends in residential energy consumption over time
* Predict what residential energy use patterns will look like over the next 5 years

### Pseudocode:

convert the yrmonth column to a date time series format
make time series data frame
visualize data using ggplot / geom_line
average the energy consumption by year (?) 
filter for only the residential data
decompose data to look for trends and seasonality
break apart by month / look for seasonality
forecasting once we have looked at the trends 
select suitable prediction model
define the alpha value (for exponential smoothing)

```{r}
energy_ts <- energy_df %>% 
  mutate(date = tsibble::yearmonth(yrmonth)) %>% # another function to convert to date
  as_tsibble(key = sector,  # use sector as our key. can have one date for 3 dif obs (differ by sector)
             index = date)
```

```{r}
ggplot(data = energy_ts, aes(x = date, y = energy_total, color = sector)) +
  geom_line() +
  labs(x = 'Date', y = 'Energy consumption by sector \n (Trillion BTUs)') +
  facet_wrap(~ sector, ncol = 1)
```

* Residential looks similar to commercial, with an upward trend at least for the first part, mayble leveling off or decreasing in recent years
* Seasonality - summer and winter peaks, summer peaks (the smaller ones) seem to be getting larger over time

### Season plot

```{r}
energy_ts %>% 
  filter(sector == 'residential') %>% 
  gg_season(y = energy_total, pal = hcl.colors(n = 9)) + 
  theme_light() +
  labs(x = 'Month', y = 'Residential energy consumption (trillion BTU)')
# can see seasonality, as well as how years differ from each other
```

### Subseries plot

```{r}
energy_ts %>% 
  gg_subseries(y = energy_total) # breaks down data by month and sector over the time period
```

## Decomposition

```{r}
### Find the STL decomposition (L = LOESS = Locally Estimated Scatterplot Smoothing)

dcmp <- energy_ts %>% 
  filter(sector == 'residential') %>% 
  model(feasts::STL(energy_total ~ season(period = '1 year') +
                      trend(window = 49))) # create STL model. defining your season and trend

components(dcmp) %>% 
  autoplot() # autoplot helps convert model output into a typical plot
  # shows your data, and then the trend, seasonal component, and remainder
```

### Autocorrelation function

```{r}
energy_ts %>% 
  filter(sector == 'residential') %>% 
  ACF(energy_total) %>% # creates ACF model (autocorrelation function)
  autoplot()
# compares data using lag times
# can see: how far out can you find good correlations? can you use 12 months out? what about 24?
```

### Forecasting by Holdt Winters exponential smoothing

Specify for each component, whether none ("N"), additive ("A"), or multiplicative ("M")

```{r}
### Create a model
energy_fit <- energy_ts %>% 
  filter(sector == 'residential') %>% 
  filter_index('2010-01' ~ .) %>% 
  model(ets = ETS(energy_total ~ season(method = "M") + trend(method = "A"))) # exponential time smoothing

energy_forecast <- energy_fit %>% # put fit model into forecast function, tell it what time span to forecast
  forecast(h = "5 years")

energy_forecast %>% 
  autoplot(energy_ts) # can plot your actual data and add on your forecast
```

```{r}
energy_predicted <- energy_fit %>% 
  broom::augment()

# compare model to actual data
ggplot(energy_predicted) +
  geom_line(aes(x = date, y = energy_total)) +
  geom_line(aes(x = date, y = .fitted), color = 'red', alpha = 0.7)

ggplot(energy_predicted, aes(x = .resid)) +
  geom_histogram()
```





